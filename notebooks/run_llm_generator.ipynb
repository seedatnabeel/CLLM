{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "\n",
    "from src.utils import *\n",
    "from src.llm_gen import *\n",
    "from src.dataset_llm_templates import *\n",
    "from src.data_loader import *\n",
    "\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# API KEY SETUP INSTRUCTIONS\n",
    "\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# for vllm\n",
    "# api_key = \"EMPTY\"\n",
    "# api_base = \"http://localhost:8000/v1\"\n",
    "\n",
    "# for together\n",
    "# api_key = \"add together api key\"\n",
    "# api_base = \"https://api.together.xyz/v1\"\n",
    "\n",
    "\n",
    "# for azure openai\n",
    "# api_key = \"EMPTY\"\n",
    "# api_base = \"add azure deployment link\"\n",
    "\n",
    "# for openai\n",
    "# api_key = \"EMPTY\"\n",
    "# api_base = DO NOT INCLUDE\n",
    "#############################################################\n",
    "\n",
    "api_details = {\n",
    "     \"api_base\": \"add api base\",\n",
    "     \"api_version\": \"2023-07-01-preview\",\n",
    "     \"api_key\": \"add api key\",\n",
    "}\n",
    "\n",
    "\n",
    "model_short_name = 'mixtral' # 'gpt-4' (do not use other short names)\n",
    "model = \"mistralai/Mixtral-8x7B-Instruct-v0.1\" # \"gpt4_20230815\" (use name of your model deployment)\n",
    "llm_serving='together' # supported 'azure_openai', 'together', 'vllm'\n",
    "\n",
    "\n",
    "# Factors to evaluate\n",
    "seeds = [0,1,2,3,4,5,6,7,8,9]\n",
    "n_samples = [10,20,50,100]  # e.g. 10 *2 = 20, 20*2 = 40, 50*2 = 100, 100*2 = 200\n",
    "datasets = ['compas']\n",
    "\n",
    "for seed in seeds:\n",
    "    for ns in n_samples: \n",
    "        for dataset in datasets:\n",
    "            try:\n",
    "                # sleep between runs from a rate limit perspective\n",
    "                # time.sleep(120)\n",
    "                n_synthetic=20\n",
    "                n_processes = 5\n",
    "\n",
    "                df_feat, df_label, df = get_data(dataset=dataset, seed=seed)\n",
    "\n",
    "\n",
    "                X_train, X_remain, y_train, y_remain = sample_and_split(df_feat, df_label, ns=ns, seed=seed)\n",
    "\n",
    "                X_val, X_test, y_val, y_test = train_test_split(\n",
    "                    X_remain, y_remain, test_size=0.5, random_state=seed\n",
    "                )\n",
    "\n",
    "\n",
    "                X_train_orig = deepcopy(X_train)\n",
    "                y_train_orig = deepcopy(y_train)\n",
    "\n",
    "                results = {}\n",
    "                results['Original'] = {\"X\": X_train_orig, 'y': y_train_orig}\n",
    "                results['Oracle'] = {\"X\": X_val, 'y': y_val}\n",
    "                results['Test'] = {\"X\": X_test, 'y': y_test}\n",
    "\n",
    "\n",
    "                prompt, generator_template, format_instructions, example_df = langchain_templates(X_train_orig, y_train_orig, dataset=dataset)\n",
    "\n",
    "                retries = 4  # Max retries you want to attempt\n",
    "\n",
    "                while retries > 0:\n",
    "                    try:\n",
    "\n",
    "                        if len(example_df)>20:\n",
    "                            ic_samples=20\n",
    "                        else:\n",
    "                            ic_samples=len(example_df)\n",
    "                        \n",
    "                        print(f'Running {dataset}, {seed}, {model} --- {n_processes}')\n",
    "                        df_llm = llm_gen(prompt, generator_template, format_instructions, example_df, \n",
    "                                        n_samples=n_synthetic,\n",
    "                                        temperature=0.9,\n",
    "                                        max_tokens=1000, model=model, \n",
    "                                        n_processes=n_processes,\n",
    "                                        ic_samples=ic_samples, \n",
    "                                        llm_serving=llm_serving, \n",
    "                                        api_details=api_details)\n",
    "                        print(df_llm.shape)\n",
    "                        break  # if successful, break out of the loop\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error: {e}. Retrying with reduced n_processes...\")\n",
    "                        n_processes = int(n_processes/2)\n",
    "                        retries -= 1\n",
    "                        if n_processes < 1:\n",
    "                            print(\"Error: Minimum n_processes reached. Exiting...\")\n",
    "                            break\n",
    "                try:\n",
    "                    tmp_df = df_llm.astype(example_df.dtypes)\n",
    "                    df_llm = tmp_df\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                ylabel_map = {'covid': \"is_dead\",\n",
    "                            \"adult\": \"salary\",\n",
    "                            \"compas\": \"y\",\n",
    "                            \"drug\": \"y\",\n",
    "                            \"bio\": \"y\",\n",
    "                            \"higgs\": \"y\",\n",
    "                            \"seer\": \"mortCancer\",\n",
    "                            \"cutract\":\"mortCancer\",\n",
    "                            \"maggic\": \"death_all\",\n",
    "                            \"support\": \"death\",\n",
    "                            }\n",
    "                \n",
    "                ylabel =  ylabel_map[dataset]\n",
    "\n",
    "                X_train_llm = df_llm.drop(columns=[ylabel])\n",
    "                y_train_llm = df_llm[ylabel]\n",
    "\n",
    "                results['llm'] = {\"X\": X_train_llm, 'y': y_train_llm, 'df': df}\n",
    "\n",
    "\n",
    "                with open(f'../save_dfs/pipeline_llm_{dataset}_{n_synthetic}_{model_short_name}_{ns}_{seed}.pickle', 'wb') as f:\n",
    "                        pickle.dump(results, f)\n",
    "\n",
    "            except Exception as e:\n",
    "                import traceback\n",
    "                print(traceback.format_exc())\n",
    "                print(e)\n",
    "                continue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
